{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f877c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from   bs4 import BeautifulSoup\n",
    "import os\n",
    "import glob\n",
    "from   zipfile import ZipFile\n",
    "from   easymore.easymore import easymore\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import datetime\n",
    "import xarray as xr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c97dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the unzip\n",
    "def HYDAT_download(url, folder_to_save):\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    links = []\n",
    "    for link in soup.find_all(\"a\"):\n",
    "        href = link.get(\"href\")\n",
    "        if href and href.startswith(\"Hydat_sqlite3\") and href.endswith(\".zip\"):\n",
    "            links.append(href)\n",
    "\n",
    "    if len(links) == 1:\n",
    "        HYDAT_link = url+links[0]\n",
    "    else:\n",
    "        print('There are multiple files in links')\n",
    "\n",
    "    if not os.path.isdir(folder_to_save):\n",
    "        os.makedirs(folder_to_save)\n",
    "\n",
    "    r = requests.get(HYDAT_link) # download the URL\n",
    "    # print the specification of the download \n",
    "    print(r.status_code, r.headers['content-type'], r.encoding)\n",
    "    # if download successful the statuse code is 200 then save the file, else print what was not downloaded\n",
    "    if r.status_code == 200:\n",
    "        print('download was successful for '+url)\n",
    "        with open(folder_to_save+ 'HYDAT.zip', 'wb') as f:\n",
    "            f.write(r.content)\n",
    "    else:\n",
    "        print('download was not successful for '+url)\n",
    "    \n",
    "    # unzip the folder\n",
    "    name_zips = glob.glob(folder_to_save+ 'HYDAT.zip')  # getting the name of the all the downloaded zip file in one directory\n",
    "    # loop over the zip file names and unzip them\n",
    "    for name_zip in name_zips:\n",
    "        with ZipFile(name_zip, 'r') as zipObj:\n",
    "            # Extract all the contents of zip file in different directory\n",
    "            folder_name = name_zip[:-4] # removing the zip extension (.zip)\n",
    "            zipObj.extractall(folder_to_save)\n",
    "\n",
    "def get_the_daily_dataframe(\n",
    "    df: pd.DataFrame,\n",
    "    regex_str: str,\n",
    "    col: str,\n",
    "    *args,\n",
    "    **kwargs,\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    # filter and trim columns\n",
    "    df = df.filter(regex=regex_str, axis=1) # extract the columns\n",
    "    df.columns = df.columns.str.replace(r'\\D', '', regex=True) # remove non-digits\n",
    "    df = df.stack(dropna=False) # stack without dropping\n",
    "    df.index.names = ['STATION_NUMBER', 'YEAR', 'MONTH', 'DAY'] # assign index names\n",
    "    df = df.reset_index() # reset index to add another level\n",
    "    df['DATE'] = pd.to_datetime(df[['YEAR', 'MONTH', 'DAY']].astype(str).agg('-'.join, axis=1),\\\n",
    "                                errors='coerce') # define date column\n",
    "    df.drop(columns=['YEAR', 'MONTH', 'DAY'], inplace=True) # drop unnecessary columns\n",
    "    df.dropna(subset=['DATE'], inplace=True) # remove invalid dates\n",
    "    df.set_index(keys=['STATION_NUMBER', 'DATE'], drop=True, inplace=True) # set index levels\n",
    "    df.columns = [col] # assing column name\n",
    "    \n",
    "    # pivot data to look nice\n",
    "    df = df.unstack(level='STATION_NUMBER')\n",
    "    df = df.reorder_levels(order=[1,0], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_station_daily_flow(\n",
    "    station: str,\n",
    "    connection: str, # sqlite3 file location\n",
    "    start_date: str = '1850-01-01',\n",
    "    end_date: str = str(datetime.datetime.now().date()),\n",
    "    *args,\n",
    "    **kwargs,\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    '''\n",
    "    This function simply extracts data from the HYDAT sqlite3 database\n",
    "    '''\n",
    "    \n",
    "    connection = sqlite3.connect(connection)\n",
    "    \n",
    "    # read station data\n",
    "    df = pd.read_sql_query(f\"SELECT * FROM DLY_FLOWS WHERE STATION_NUMBER LIKE '%{station}%'\", connection)\n",
    "    \n",
    "    # set index\n",
    "    df.set_index(keys=['STATION_NUMBER', 'YEAR', 'MONTH'], drop=True, inplace=True)\n",
    "    \n",
    "    # get the FLOW and FLAG\n",
    "    df_flow = get_the_daily_dataframe(df, r'^FLOW\\d', 'FLOW')\n",
    "    df_flag = get_the_daily_dataframe(df, r'^FLOW_.', 'FLAG')\n",
    "    \n",
    "    #\n",
    "    df_flow.sort_index(axis=0, inplace=True)\n",
    "    df_flow.sort_index(axis=1, level=0, ascending=False, inplace=True)\n",
    "    df_flow.columns = df_flow.columns.droplevel(1)\n",
    "    df_flow.columns.name = None\n",
    "    \n",
    "    df_flag.sort_index(axis=0, inplace=True)\n",
    "    df_flag.sort_index(axis=1, level=0, ascending=False, inplace=True)\n",
    "    df_flag.columns = df_flag.columns.droplevel(1)\n",
    "    df_flag.columns.name = None\n",
    "    \n",
    "    df_flow = df_flow.loc[start_date:end_date, :]\n",
    "    df_flag = df_flag.loc[start_date:end_date, :]\n",
    "    \n",
    "    # stations information\n",
    "    df_info = pd.read_sql_query(f\"SELECT * FROM STATIONS WHERE STATION_NUMBER LIKE '%{station}%'\", connection)\n",
    "    \n",
    "    return df_flow, df_flag, df_info\n",
    "\n",
    "def get_all_stations_with_daily_flow(\n",
    "    connection: str, # sqlite3 file location\n",
    "    )-> list:\n",
    "    \n",
    "    connection = sqlite3.connect(connection)\n",
    "    \n",
    "    # Create a cursor object\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Construct the SQL statement to retrieve the unique STATION_NUMBER values\n",
    "    table_name = 'DLY_FLOWS'\n",
    "    column_name = 'STATION_NUMBER'\n",
    "    sql = \"SELECT DISTINCT {} FROM {}\".format(column_name, table_name)\n",
    "\n",
    "    # Execute the SQL statement\n",
    "    cursor.execute(sql)\n",
    "\n",
    "    # Fetch the results\n",
    "    results = cursor.fetchall() \n",
    "    results = [str(x).replace('(', '').replace(')', '').replace(',', '') for x in results]\n",
    "    results = [x.replace(\"'\", \"\") for x in results]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_csv_nc(HYDAT_sqlite_location,\n",
    "                  folder_to_save,\n",
    "                  station,\n",
    "                  save_nc = False,\n",
    "                  start_date: str = '1850-01-01',\n",
    "                  end_date: str = str(datetime.datetime.now().date()),):\n",
    "    \n",
    "    if not os.path.isdir(folder_to_save):\n",
    "        os.makedirs(folder_to_save)\n",
    "\n",
    "    df_flow, df_flag, df_info = extract_station_daily_flow(station,\n",
    "                                                           HYDAT_sqlite_location,\n",
    "                                                           start_date=start_date,\n",
    "                                                           end_date=end_date)\n",
    "    # save the csv\n",
    "    df_flow.to_csv(folder_to_save+station+'_Flow.csv')\n",
    "    df_flag.to_csv(folder_to_save+station+'_Flag.csv')\n",
    "    df_info.to_csv(folder_to_save+station+'_Info.csv')\n",
    "    # save to netcdf using easymore\n",
    "    if save_nc:\n",
    "        esmr = easymore()\n",
    "        ds_flow = esmr.dataframe_to_netcdf_xr(df_flow,\n",
    "                                              variable_name = 'Flow',\n",
    "                                              unit_of_variable = 'm**3 s**-1',\n",
    "                                              variable_long_name = 'daily discharge from HYDAT dataset',\n",
    "                                              Fill_value = '-9999',\n",
    "                                              station_info_data = df_info,\n",
    "                                              station_info_column = 'STATION_NUMBER')\n",
    "                                              #  nc_file_name = station+'_Flow.nc',\n",
    "                                              #  nc_file_path = folder_to_save,\n",
    "        ds_flag = esmr.dataframe_to_netcdf_xr(df_flag,\n",
    "                                              variable_name = 'Flag',\n",
    "                                              unit_of_variable = '-',\n",
    "                                              variable_long_name = 'flag for daily discharge from HYDAT dataset',\n",
    "                                              Fill_value = '-9999',\n",
    "                                              station_info_data = df_info,\n",
    "                                              station_info_column = 'STATION_NUMBER')\n",
    "                                              #  nc_file_name = station+'_Flag.nc',\n",
    "                                              #  nc_file_path = folder_to_save,\n",
    "        ds = xr.merge([ds_flow,ds_flag])\n",
    "        if os.path.isfile(folder_to_save+station+'.nc'):\n",
    "            os.remove(folder_to_save+station+'.nc')\n",
    "        ds.to_netcdf(folder_to_save+station+'.nc')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca9f9705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EASYMORE version 0.0.5 is initiated.\n",
      "EASYMORE detects that the input datafarame is pandas dataframe\n",
      "EASYMORE detects that index is pandas datatime\n",
      "EASYMORE detects that the station data is pandas dataframe\n",
      "EASYMORE detects that the necessary information for the station are provided with transpose\n",
      "{'Flow': {'dtype': 'object', '_FillValue': -9999}}\n",
      "EASYMORE detects that the input datafarame is pandas dataframe\n",
      "EASYMORE detects that index is pandas datatime\n",
      "EASYMORE detects that the station data is pandas dataframe\n",
      "EASYMORE detects that the necessary information for the station are provided with transpose\n",
      "{'Flag': {'dtype': 'object'}}\n",
      "EASYMORE version 0.0.5 is initiated.\n",
      "EASYMORE detects that the input datafarame is pandas dataframe\n",
      "EASYMORE detects that index is pandas datatime\n",
      "EASYMORE detects that the station data is pandas dataframe\n",
      "EASYMORE detects that the necessary information for the station are provided with transpose\n",
      "{'Flow': {'dtype': 'object', '_FillValue': -9999}}\n",
      "EASYMORE detects that the input datafarame is pandas dataframe\n",
      "EASYMORE detects that index is pandas datatime\n",
      "EASYMORE detects that the station data is pandas dataframe\n",
      "EASYMORE detects that the necessary information for the station are provided with transpose\n",
      "{'Flag': {'dtype': 'object'}}\n",
      "EASYMORE version 0.0.5 is initiated.\n",
      "EASYMORE detects that the input datafarame is pandas dataframe\n",
      "EASYMORE detects that index is pandas datatime\n",
      "EASYMORE detects that the station data is pandas dataframe\n",
      "EASYMORE detects that the necessary information for the station are provided with transpose\n",
      "{'Flow': {'dtype': 'object', '_FillValue': -9999}}\n",
      "EASYMORE detects that the input datafarame is pandas dataframe\n",
      "EASYMORE detects that index is pandas datatime\n",
      "EASYMORE detects that the station data is pandas dataframe\n",
      "EASYMORE detects that the necessary information for the station are provided with transpose\n",
      "{'Flag': {'dtype': 'object'}}\n",
      "EASYMORE version 0.0.5 is initiated.\n",
      "EASYMORE detects that the input datafarame is pandas dataframe\n",
      "EASYMORE detects that index is pandas datatime\n",
      "EASYMORE detects that the station data is pandas dataframe\n",
      "EASYMORE detects that the necessary information for the station are provided with transpose\n",
      "{'Flow': {'dtype': 'object', '_FillValue': -9999}}\n",
      "EASYMORE detects that the input datafarame is pandas dataframe\n",
      "EASYMORE detects that index is pandas datatime\n",
      "EASYMORE detects that the station data is pandas dataframe\n",
      "EASYMORE detects that the necessary information for the station are provided with transpose\n",
      "{'Flag': {'dtype': 'object'}}\n",
      "EASYMORE version 0.0.5 is initiated.\n",
      "EASYMORE detects that the input datafarame is pandas dataframe\n",
      "EASYMORE detects that index is pandas datatime\n",
      "EASYMORE detects that the station data is pandas dataframe\n",
      "EASYMORE detects that the necessary information for the station are provided with transpose\n",
      "{'Flow': {'dtype': 'object', '_FillValue': -9999}}\n",
      "EASYMORE detects that the input datafarame is pandas dataframe\n",
      "EASYMORE detects that index is pandas datatime\n",
      "EASYMORE detects that the station data is pandas dataframe\n",
      "EASYMORE detects that the necessary information for the station are provided with transpose\n",
      "{'Flag': {'dtype': 'object'}}\n"
     ]
    }
   ],
   "source": [
    "# inputs\n",
    "url = \"https://collaboration.cmc.ec.gc.ca/cmc/hydrometrics/www/\" # url may not change but better to check\n",
    "folder_to_save = './HYDAT/' # place where the files are saved\n",
    "\n",
    "# download the HYDAT data if already not donwloaded\n",
    "HYDAT_download(url, folder_to_save)\n",
    "\n",
    "# get all the station starting with 05BB\n",
    "create_csv_nc(folder_to_save+'Hydat.sqlite3', folder_to_save, '05BB', save_nc = True) \n",
    "\n",
    "# loop over all the station with flow variable\n",
    "all_station_with_Flow = get_all_stations_with_daily_flow (folder_to_save+'Hydat.sqlite3')\n",
    "all_station_with_Flow = all_station_with_Flow[0:4] # just the first four, this can be commneted if all stations are needed\n",
    "for station in all_station_with_Flow:\n",
    "    create_csv_nc(folder_to_save+'Hydat.sqlite3', folder_to_save, station, save_nc = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b157111e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Frozen' object has no attribute 'to_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yh/b1qy7zb96k980mcb2ps9n6d9t1c6zr/T/ipykernel_57899/247003988.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_to_save\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'05BB.nc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mds_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'05BB001'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_slice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mds_slice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Frozen' object has no attribute 'to_list'"
     ]
    }
   ],
   "source": [
    "# plot for a given station\n",
    "ds = xr.open_dataset(folder_to_save+'05BB.nc')\n",
    "ds_slice = ds.sel(n='05BB001')\n",
    "print(ds_slice.variables)\n",
    "ds_slice.Flow.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb7ec6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv38",
   "language": "python",
   "name": "myenv38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
